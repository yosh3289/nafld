{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **装包和数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tableone import TableOne, load_dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "import pyreadstat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn import metrics\n",
    "from matplotlib.pyplot import cm\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupKFold, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import cupy as cp\n",
    "import xgboost as xgb\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.zeros(1).cuda())\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 3.1 定义分类特征 -----------------------\n",
    "# 分类特征分为二分类和多分类\n",
    "binary_features = [\n",
    "    'Sex', \n",
    "    'history of hypertension', \n",
    "    'history of diabetes', \n",
    "    'elevated blood glucose',\n",
    "    'history of hyperlipidemia', \n",
    "    'coronary heart disease', \n",
    "    'stroke',\n",
    "    'history of tumor', \n",
    "    'hypertensive medications', \n",
    "    'lipid-lowering drugs', \n",
    "    'glucose-lowering drugs'\n",
    "]\n",
    "\n",
    "multi_class_features = [\n",
    "    'smoking', \n",
    "    'alcohol'\n",
    "]\n",
    "\n",
    "# 合并所有分类特征\n",
    "categorical_features = binary_features + multi_class_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 3.2 独立记录特征 (Record-Level) -----------------------\n",
    "X_independent = train_df.drop(columns=['NAFLD', 'PatientID'])  # 这里保留 'Nth_record_for_patient' 和其他特征\n",
    "y_independent = train_df['NAFLD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 3.3 患者历史记录特征 (Patient-Level) -----------------\n",
    "# 定义加权聚合函数\n",
    "def exponential_weighted_feature(grp, alpha=0.7):\n",
    "    \"\"\"\n",
    "    为每位患者的每条记录计算指数加权移动平均（EWMA）特征。\n",
    "    \n",
    "    参数：\n",
    "    - grp: 按PatientID分组后的单个子DataFrame。\n",
    "    - alpha: 权重衰减因子，值越大，近期记录权重越大。\n",
    "    \n",
    "    返回：\n",
    "    - 带有新加权特征的DataFrame。\n",
    "    \"\"\"\n",
    "    # 按ExamYear排序\n",
    "    grp = grp.sort_values('ExamYear')\n",
    "    \n",
    "    # 对每个数值特征应用EWMA\n",
    "    numeric_features = grp.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    # 排除 'Nth_record_for_patient' 和 'ExamYear'（如果不需要）\n",
    "    if 'Nth_record_for_patient' in numeric_features:\n",
    "        numeric_features.remove('Nth_record_for_patient')\n",
    "    if 'ExamYear' in numeric_features:\n",
    "        numeric_features.remove('ExamYear')\n",
    "    if 'PatientID' in numeric_features:\n",
    "        numeric_features.remove('PatientID')\n",
    "    \n",
    "    for feature in numeric_features:\n",
    "        # ewma_col = f'{feature}_ewma'\n",
    "        grp[feature] = grp[feature].ewm(alpha=alpha).mean()\n",
    "    \n",
    "    return grp\n",
    "\n",
    "# 应用加权聚合\n",
    "df_sorted = train_df.sort_values(by=['PatientID', 'ExamYear'])\n",
    "df_ewm = df_sorted.groupby('PatientID').apply(exponential_weighted_feature, alpha=0.7).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ewm column names\n",
    "df_ewm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 4.1 计算患者历史记录数量并生成动态权重 -------------------------\n",
    "# 根据数据 test_df 中每位患者出现的次数来决定“独立记录模型”与“患者记录模型”的权重\n",
    "patient_record_counts = test_df.groupby('PatientID').size()\n",
    "max_records = patient_record_counts.max()\n",
    "min_records = patient_record_counts.min()\n",
    "\n",
    "# 使用对数缩放计算权重，以平滑权重分布\n",
    "patient_weights = np.log1p(patient_record_counts - min_records) / np.log1p(max_records - min_records)\n",
    "\n",
    "# 计算 alpha 值（独立记录模型的权重）\n",
    "alpha = 1 - patient_weights\n",
    "\n",
    "# 将 alpha 映射回每条独立记录\n",
    "alpha_full = test_df['PatientID'].map(alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型训练和预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算 train_df 当中阳性样本和阴性样本的比例以用于 scale_pos_weight 参数\n",
    "# 计算正类和负类的数量\n",
    "num_positive = np.sum(train_df['NAFLD'] == 1)  # 患病样本的数量\n",
    "num_negative = np.sum(train_df['NAFLD'] == 0)  # 无病样本的数量\n",
    "\n",
    "# 计算 scale_pos_weight\n",
    "scale_pos_weight = num_negative / num_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pos_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 5.1 独立记录模型 (模型1) -------------------------\n",
    "# 定义列变换器\n",
    "# 检查是否有GPU可用\n",
    "gpu_available = cp.cuda.is_available()\n",
    "\n",
    "# 定义列变换器\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # 保留其他数值特征\n",
    ")\n",
    "\n",
    "# 创建管道\n",
    "pipeline_independent = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb.XGBClassifier(\n",
    "        use_label_encoder=False, \n",
    "        eval_metric='logloss', \n",
    "        random_state=42,\n",
    "        tree_method='gpu_hist' if gpu_available else 'auto',  # 启用GPU计算\n",
    "        gpu_id=0 if gpu_available else None,  # 如果有GPU可用，指定GPU ID\n",
    "        scale_pos_weight=scale_pos_weight,  # 根据数据不平衡情况调整此值\n",
    "        enable_categorical=True\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 使用 GroupKFold 进行交叉验证（确保每个患者的所有记录在同一折中）\n",
    "group_cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# 设置GridSearchCV来寻找最佳超参数\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__subsample': [0.7, 0.8, 0.9],\n",
    "    'classifier__colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# 初始化 GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline_independent,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',  # 使用AUC作为评价指标\n",
    "    cv=group_cv,  # 使用GroupKFold进行分组交叉验证\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 训练GridSearchCV，传递'groups'参数\n",
    "Ags = grid_search.fit(train_df.drop(columns=['NAFLD', 'PatientID','ExamYear']), train_df['NAFLD'], groups=train_df['PatientID'])\n",
    "\n",
    "# 输出最优超参数\n",
    "print(f\"Best Parameters for Independent Model: {Ags.best_params_}\")\n",
    "\n",
    "# 获取最佳模型\n",
    "best_model_independent = Ags.best_estimator_\n",
    "\n",
    "# 使用最佳模型在全量数据上进行训练\n",
    "best_independent = best_model_independent.fit(train_df.drop(columns=['NAFLD', 'PatientID','ExamYear']), train_df['NAFLD'])\n",
    "\n",
    "# 预测概率\n",
    "y_pred_independent = best_independent.predict_proba(test_df.drop(columns=['NAFLD','PatientID','ExamYear']))[:, 1]\n",
    "\n",
    "# 保存最佳模型\n",
    "joblib.dump(best_independent, 'best_independent_model.pkl')\n",
    "\n",
    "# 加载最佳模型\n",
    "# best_model_independent = joblib.load('best_independent_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 3.1 定义分类特征 -----------------------\n",
    "# 分类特征分为二分类和多分类\n",
    "binary_features = [\n",
    "    'Sex', \n",
    "    'history of hypertension', \n",
    "    'history of diabetes', \n",
    "    'elevated blood glucose',\n",
    "    'history of hyperlipidemia', \n",
    "    'coronary heart disease', \n",
    "    'stroke',\n",
    "    'history of tumor', \n",
    "    'hypertensive medications', \n",
    "    'lipid-lowering drugs', \n",
    "    'glucose-lowering drugs'\n",
    "]\n",
    "\n",
    "multi_class_features = [\n",
    "    'smoking', \n",
    "    'alcohol'\n",
    "]\n",
    "\n",
    "# 合并所有分类特征\n",
    "categorical_features = binary_features + multi_class_features\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 5.2 患者记录模型 (模型2) ------------------------- #\n",
    "# 判断是否有GPU可用\n",
    "gpu_available = cp.cuda.is_available()\n",
    "# 定义列变换器\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # 保留其他数值特征\n",
    ")\n",
    "\n",
    "# 创建管道\n",
    "pipeline_patient = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', xgb.XGBClassifier(\n",
    "        use_label_encoder=False, \n",
    "        eval_metric='logloss', \n",
    "        random_state=42,\n",
    "        tree_method='gpu_hist' if gpu_available else 'auto',  # 启用GPU计算\n",
    "        gpu_id=0 if gpu_available else None,  # 如果有GPU可用，指定GPU ID\n",
    "        scale_pos_weight=scale_pos_weight,  # 根据数据不平衡情况调整此值\n",
    "        enable_categorical=True\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 使用 GroupKFold 进行交叉验证（确保每个患者的所有记录在同一折中）\n",
    "group_cv = GroupKFold(n_splits=5)\n",
    "\n",
    "# 设置GridSearchCV来寻找最佳超参数\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__subsample': [0.7, 0.8, 0.9],\n",
    "    'classifier__colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# 初始化 GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline_patient,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    cv=group_cv,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 训练 GridSearchCV，传递 'groups' 参数\n",
    "Bgs = grid_search.fit(df_ewm.drop(columns=['NAFLD', 'PatientID','ExamYear']), df_ewm['NAFLD'], groups=df_ewm['PatientID'])\n",
    "\n",
    "print(f\"Best Parameters for Patient Model: {grid_search.best_params_}\")\n",
    "best_model_patient = Bgs.best_estimator_\n",
    "\n",
    "# 在全量训练数据上训练最佳模型\n",
    "best_patient = best_model_patient.fit(df_ewm.drop(columns=['NAFLD', 'PatientID','ExamYear']), df_ewm['NAFLD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测患者级的概率\n",
    "y_pred_patient_full = best_patient.predict_proba(test_df.drop(columns=['NAFLD', 'PatientID','ExamYear']))[:, 1]\n",
    "\n",
    "# 使用 joblib 保存最佳模型\n",
    "joblib.dump(best_patient, 'best_patient_model.pkl')\n",
    "\n",
    "# 加载最佳模型（如果需要）\n",
    "# best_model_patient = joblib.load('best_patient_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 6.1 动态加权融合预测 ------------------------- #\n",
    "# 确保以下变量已存在：\n",
    "# y_pred_independent: 独立记录模型的预测概率\n",
    "# y_pred_patient_full: 患者记录模型的预测概率\n",
    "# alpha_full: 每条记录的权重\n",
    "\n",
    "# 计算最终融合概率\n",
    "y_pred_combined = alpha_full * y_pred_independent + (1 - alpha_full) * y_pred_patient_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 7.1 模型评估和可视化 ------------------------- #\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, confusion_matrix, roc_curve\n",
    ")\n",
    "\n",
    "# 计算不同阈值下的指标变化\n",
    "thresholds_plot = np.linspace(0, 1, 100)\n",
    "metrics = {'Threshold': [], 'Accuracy': [], 'Sensitivity': [], 'Specificity': [], 'AUROC': []}\n",
    "\n",
    "for thresh in thresholds_plot:\n",
    "    y_pred_thresh = (y_pred_combined >= thresh).astype(int)\n",
    "    cm_thresh = confusion_matrix(test_df['NAFLD'], y_pred_thresh)\n",
    "    if cm_thresh.size == 1:\n",
    "        tn, fp, fn, tp = 0, 0, 0, cm_thresh[0,0]\n",
    "    elif cm_thresh.shape == (2, 2):\n",
    "        tn, fp, fn, tp = cm_thresh.ravel()\n",
    "    else:\n",
    "        tn, fp, fn, tp = 0, 0, 0, 0  # 根据实际情况调整\n",
    "    \n",
    "    accuracy_thresh = accuracy_score(test_df['NAFLD'], y_pred_thresh)\n",
    "    sensitivity_thresh = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    specificity_thresh = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "    auroc_thresh = roc_auc_score(test_df['NAFLD'], y_pred_combined)  # 计算AUROC\n",
    "\n",
    "    # 将结果存储到字典中\n",
    "    metrics['Threshold'].append(thresh)\n",
    "    metrics['Accuracy'].append(accuracy_thresh)\n",
    "    metrics['Sensitivity'].append(sensitivity_thresh)\n",
    "    metrics['Specificity'].append(specificity_thresh)\n",
    "    metrics['AUROC'].append(auroc_thresh)\n",
    "\n",
    "# 转换为DataFrame\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "\n",
    "# 绘制指标变化曲线\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(metrics_df['Threshold'], metrics_df['Accuracy'], label='Accuracy')\n",
    "plt.plot(metrics_df['Threshold'], metrics_df['Sensitivity'], label='Sensitivity')\n",
    "plt.plot(metrics_df['Threshold'], metrics_df['Specificity'], label='Specificity')\n",
    "plt.plot(metrics_df['Threshold'], metrics_df['AUROC'], label='AUROC', linestyle='--')  # 添加AUROC的变化曲线\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Metric Value')\n",
    "plt.title('Performance Metrics at Different Thresholds')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the threshold where the sum of sensitivity and specificity and accuracy and auroc is maximized\n",
    "metrics_df['Sum'] = metrics_df['Accuracy'] + metrics_df['Sensitivity'] + metrics_df['Specificity'] + metrics_df['AUROC']\n",
    "max_sum_idx = metrics_df['Sum'].idxmax()\n",
    "best_threshold = metrics_df['Threshold'][max_sum_idx]\n",
    "print(best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 7.2 最优Threshold模型评估和可视化 ------------------------- #\n",
    "# 使用 0.5 作为阈值进行二分类预测\n",
    "y_pred_labels = (y_pred_combined >= best_threshold).astype(int)\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(test_df['NAFLD'], y_pred_labels)\n",
    "if cm.shape == (1, 1):\n",
    "    tn, fp, fn, tp = 0, 0, 0, cm[0,0]\n",
    "elif cm.shape == (2, 2):\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "else:\n",
    "    tn, fp, fn, tp = 0, 0, 0, 0  # 根据实际情况调整\n",
    "\n",
    "# 计算各项指标\n",
    "accuracy = accuracy_score(test_df['NAFLD'], y_pred_labels)\n",
    "auroc = roc_auc_score(test_df['NAFLD'], y_pred_combined)\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "\n",
    "print(\"=== Evaluation Results ===\")\n",
    "print(f\"Accuracy   : {accuracy:.4f}\")\n",
    "print(f\"AUROC      : {auroc:.4f}\")\n",
    "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "\n",
    "# 绘制ROC曲线\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, thresholds_roc = roc_curve(test_df['NAFLD'], y_pred_combined)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (AUROC = {auroc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # 随机猜测的参考线\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.title('ROC Curve')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.特征重要性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 8.1 独立记录模型的特征重要性 -------------------------\n",
    "# 获取训练后的最佳模型\n",
    "model_independent_final = best_independent.named_steps['classifier']\n",
    "\n",
    "all_features = best_independent.named_steps['preprocessor'].get_feature_names_out()\n",
    "all_features = [name.replace('cat__', '').replace('remainder__', '') for name in all_features]\n",
    "\n",
    "# 获取特征重要性\n",
    "importance_independent = model_independent_final.feature_importances_\n",
    "\n",
    "# 检查特征数是否一致\n",
    "assert len(all_features) == len(importance_independent), \\\n",
    "    f\"Feature names count ({len(all_features)}) does not match importance count ({len(importance_independent)})\"\n",
    "\n",
    "# 创建特征重要性DataFrame\n",
    "feat_importance_independent = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'Importance': importance_independent\n",
    "}).sort_values(by='Importance', ascending=True)  # 排序，按重要性降序\n",
    "\n",
    "# 显示结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制特征重要性\n",
    "plt.figure(figsize=(10, 12))\n",
    "bars = plt.barh(feat_importance_independent['Feature'], feat_importance_independent['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importance (Independent Record Model)')\n",
    "\n",
    "# 在条形图末尾添加每个特征的重要性数值\n",
    "for bar in bars:\n",
    "    width = bar.get_width()  # 获取条形的宽度，即特征的重要性值\n",
    "    plt.text(width, bar.get_y() + bar.get_height() / 2, f'{width:.4f}', va='center')  # va='center' 让文本垂直居中\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 8.2 患者记录模型的特征重要性 -------------------------\n",
    "# 获取训练后的最佳模型\n",
    "model_patient_final = best_patient.named_steps['classifier']\n",
    "\n",
    "all_features = best_patient.named_steps['preprocessor'].get_feature_names_out()\n",
    "all_features = [name.replace('cat__', '').replace('remainder__', '') for name in all_features]\n",
    "\n",
    "# 获取特征重要性\n",
    "importance_Patient = model_patient_final.feature_importances_\n",
    "\n",
    "# 检查特征数是否一致\n",
    "assert len(all_features) == len(importance_Patient), \\\n",
    "    f\"Feature names count ({len(all_features)}) does not match importance count ({len(importance_Patient)})\"\n",
    "\n",
    "# 创建特征重要性DataFrame\n",
    "feat_importance_Patient = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'Importance': importance_Patient\n",
    "}).sort_values(by='Importance', ascending=True)  # 排序，按重要性降序\n",
    "\n",
    "# 显示结果\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制特征重要性\n",
    "plt.figure(figsize=(10, 12))\n",
    "bars = plt.barh(feat_importance_Patient['Feature'], feat_importance_Patient['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importance (Patient Record Model)')\n",
    "\n",
    "# 在条形图末尾添加每个特征的重要性数值\n",
    "for bar in bars:\n",
    "    width = bar.get_width()  # 获取条形的宽度，即特征的重要性值\n",
    "    plt.text(width, bar.get_y() + bar.get_height() / 2, f'{width:.4f}', va='center')  # va='center' 让文本垂直居中\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 8.3 特征重要性数据框 -------------------------\n",
    "# 合并两个模型的特征重要性\n",
    "feat_importance_combined = pd.merge(\n",
    "    feat_importance_independent, feat_importance_Patient,\n",
    "    on='Feature', suffixes=('_Independent', '_Patient')\n",
    ")\n",
    "\n",
    "# 计算两个模型的平均重要性\n",
    "feat_importance_combined['Average_Importance'] = (feat_importance_combined['Importance_Independent'] + feat_importance_combined['Importance_Patient']) / 2\n",
    "\n",
    "# 按平均重要性排序\n",
    "feat_importance_combined = feat_importance_combined.sort_values(by='Average_Importance', ascending=False)\n",
    "\n",
    "# 显示结果\n",
    "feat_importance_combined\n",
    "\n",
    "# 保存feat_importance_combined为xlxs\n",
    "feat_importance_combined.to_excel('feat_importance_combined.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. 添加基线模型进行结果比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- 3.1 定义分类特征 -----------------------\n",
    "# 分类特征分为二分类和多分类\n",
    "binary_features = [\n",
    "    'Sex', \n",
    "    'history of hypertension', \n",
    "    'history of diabetes', \n",
    "    'elevated blood glucose',\n",
    "    'history of hyperlipidemia', \n",
    "    'coronary heart disease', \n",
    "    'stroke',\n",
    "    'history of tumor', \n",
    "    'hypertensive medications', \n",
    "    'lipid-lowering drugs', \n",
    "    'glucose-lowering drugs'\n",
    "]\n",
    "\n",
    "multi_class_features = [\n",
    "    'smoking', \n",
    "    'alcohol'\n",
    "]\n",
    "\n",
    "# 合并所有分类特征\n",
    "categorical_features = binary_features + multi_class_features\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 10.1 基线模型 -------------------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "# 假设 train_df 和 test_df 已经定义，并且都包含 'PatientID' 和目标列 'NAFLD'\n",
    "# 请根据实际情况调整列名\n",
    "X_train = train_df.drop(columns=['NAFLD', 'PatientID','ExamYear'])\n",
    "y_train = train_df['NAFLD']\n",
    "X_test = test_df.drop(columns=['NAFLD', 'PatientID','ExamYear'])\n",
    "y_test = test_df['NAFLD']\n",
    "\n",
    "# 定义列变换器\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # 保留其他数值特征\n",
    ")\n",
    "\n",
    "# 定义基线模型，包括新增的 XGBoost 模型\n",
    "baseline_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Support Vector Machine': SVC(probability=True, random_state=42),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}\n",
    "\n",
    "# 用于存储交叉验证（CV）在训练集上的预测概率和在测试集上的预测概率\n",
    "baseline_cv_predictions = {}\n",
    "baseline_test_predictions = {}\n",
    "\n",
    "# 使用 train_df 中的 PatientID 作为分组进行 GroupKFold 划分\n",
    "group_kfold = GroupKFold(n_splits=5)\n",
    "\n",
    "for model_name, model in baseline_models.items():\n",
    "    print(f\"Training {model_name} with cross-validation...\")\n",
    "    # 初始化交叉验证预测概率数组\n",
    "    cv_pred = np.zeros(len(X_train))\n",
    "    \n",
    "    # 交叉验证\n",
    "    for train_idx, valid_idx in group_kfold.split(X_train, y_train, groups=train_df['PatientID']):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "        \n",
    "        # 定义 Pipeline：预处理 + 模型\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        jixian = pipeline.fit(X_tr, y_tr)\n",
    "        cv_pred[valid_idx] = pipeline.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    baseline_cv_predictions[model_name] = cv_pred\n",
    "    \n",
    "    jixian_final = jixian.fit(X_train, y_train)\n",
    "    test_pred = jixian_final.predict_proba(X_test)[:, 1]\n",
    "    baseline_test_predictions[model_name] = test_pred\n",
    "\n",
    "    # 可选：打印测试集的 ROC-AUC 分数\n",
    "    test_auc = roc_auc_score(y_test, test_pred)\n",
    "    print(f\"{model_name} Test ROC-AUC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 10.2 基线模型结果 -------------------------\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# 定义一个函数来计算特异度（Specificity），避免与全局变量冲突\n",
    "def calc_specificity(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "# 初始化评估结果字典\n",
    "evaluation_results = {\n",
    "    'AUROC': {},\n",
    "    'Accuracy': {},\n",
    "    'Recall': {},\n",
    "    'Specificity': {}\n",
    "}\n",
    "\n",
    "# 评估每个基线模型的指标\n",
    "for model_name, y_pred in baseline_test_predictions.items():\n",
    "    print(f\"\\n=== Evaluating {model_name} ===\")\n",
    "    \n",
    "    # 计算 AUROC\n",
    "    auc = roc_auc_score(test_df['NAFLD'], y_pred)\n",
    "    \n",
    "    # 将预测值转化为标签（0 或 1），用于计算 Accuracy、Recall、F1 和 Specificity\n",
    "    y_pred_label = (y_pred >= best_threshold).astype(int) # 使用与组合模型相同的阈值以确保公平比较\n",
    "    \n",
    "    # 计算 Accuracy、Recall、F1 Score 和 Specificity\n",
    "    acc = accuracy_score(test_df['NAFLD'], y_pred_label)\n",
    "    rec = recall_score(test_df['NAFLD'], y_pred_label)\n",
    "    spec = calc_specificity(test_df['NAFLD'], y_pred_label)\n",
    "    \n",
    "    # 存储各个评价指标\n",
    "    evaluation_results['AUROC'][model_name] = auc\n",
    "    evaluation_results['Accuracy'][model_name] = acc\n",
    "    evaluation_results['Recall'][model_name] = rec\n",
    "    evaluation_results['Specificity'][model_name] = spec\n",
    "\n",
    "# 纳入之前自创模型 \"xgboost combined\" 的结果\n",
    "# 假设全局变量 accuracy, auroc, sensitivity, specificity 已经在代码最开始处定义\n",
    "evaluation_results['AUROC']['XGBoost Combined'] = auroc\n",
    "evaluation_results['Accuracy']['XGBoost Combined'] = accuracy\n",
    "evaluation_results['Recall']['XGBoost Combined'] = sensitivity  # sensitivity 与 Recall 等价\n",
    "evaluation_results['Specificity']['XGBoost Combined'] = specificity\n",
    "\n",
    "# 打印评估结果\n",
    "for metric in evaluation_results:\n",
    "    print(f\"\\n{metric}:\")\n",
    "    for model_name, score in evaluation_results[metric].items():\n",
    "        print(f\"{metric} - {model_name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 10.3 绘制基线模型的 ROC 曲线 -------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# 使用 seaborn 的 Set1 色板为基线模型分配颜色\n",
    "palette = sns.color_palette(\"Set1\", n_colors=len(baseline_test_predictions))\n",
    "\n",
    "# 绘制各个基线模型的 ROC 曲线，使用不同的颜色\n",
    "for i, (model_name, y_pred) in enumerate(baseline_test_predictions.items()):\n",
    "    fpr, tpr, _ = roc_curve(test_df['NAFLD'], y_pred)\n",
    "    auc_model = roc_auc_score(test_df['NAFLD'], y_pred)\n",
    "    plt.plot(fpr, tpr, color=palette[i], label=f'{model_name} (AUROC = {auc_model:.4f})')\n",
    "\n",
    "# 绘制 XGBoost Combined 模型的 ROC 曲线，使用醒目的红色，并加粗\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(test_df['NAFLD'], y_pred_combined)\n",
    "auroc_xgb = roc_auc_score(test_df['NAFLD'], y_pred_combined)\n",
    "plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost Combined (AUROC = {auroc_xgb:.4f})',\n",
    "         linewidth=2.5, color='red')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Baseline Models and XGBoost Combined Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算模型在不同频次分组下的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 11.1 整体模型在不同频次分组下的预测效果 -------------------------\n",
    "# 将test_df分成不同频次的组，按频次<= 2, 3<= 频次 <= 5, 频次 > 5分组\n",
    "test_patientID_dict_1 = list(map(test_patientID_dict.get, [1,2]))\n",
    "test_patientID_dict_2 = list(map(test_patientID_dict.get, [3,4,5]))\n",
    "test_patientID_dict_3 = list(map(test_patientID_dict.get, [6,7,8,9,10,11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patientID_dict_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(67767 in result_list_1)\n",
    "print(67767 in result_list_2)\n",
    "print(67767 in result_list_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将test_patientID_dict_1, test_patientID_dict_2, test_patientID_dict_3里的Int64Index值提取到3个result_list当中\n",
    "result_list_1 = []\n",
    "result_list_2 = []\n",
    "result_list_3 = []\n",
    "for i in test_patientID_dict_1:\n",
    "    result_list_1.extend(i.tolist())\n",
    "for i in test_patientID_dict_2:\n",
    "    result_list_2.extend(i.tolist())\n",
    "for i in test_patientID_dict_3:\n",
    "    result_list_3.extend(i.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_1 = test_df[test_df['PatientID'].isin(result_list_1)]\n",
    "test_df_2 = test_df[test_df['PatientID'].isin(result_list_2)]\n",
    "test_df_3 = test_df[test_df['PatientID'].isin(result_list_3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将每个分组的index存储到3个字典中\n",
    "test_df_1_index = test_df_1.index\n",
    "test_df_2_index = test_df_2.index\n",
    "test_df_3_index = test_df_3.index\n",
    "\n",
    "# 从y_pred_combined中提取每个分组对应index的预测概率\n",
    "y_pred_combined_1 = y_pred_combined[test_df_1_index]\n",
    "y_pred_combined_2 = y_pred_combined[test_df_2_index]\n",
    "y_pred_combined_3 = y_pred_combined[test_df_3_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- 11.2 整体模型在不同频次分组下的accuracy和auroc -------------------------\n",
    "# 计算不同频次分组下的accuracy和auroc\n",
    "accuracy_1 = accuracy_score(test_df_1['NAFLD'], (y_pred_combined_1 >= best_threshold).astype(int))\n",
    "accuracy_2 = accuracy_score(test_df_2['NAFLD'], (y_pred_combined_2 >= best_threshold).astype(int))\n",
    "accuracy_3 = accuracy_score(test_df_3['NAFLD'], (y_pred_combined_3 >= best_threshold).astype(int))\n",
    "\n",
    "auroc_1 = roc_auc_score(test_df_1['NAFLD'], y_pred_combined_1)\n",
    "auroc_2 = roc_auc_score(test_df_2['NAFLD'], y_pred_combined_2)\n",
    "auroc_3 = roc_auc_score(test_df_3['NAFLD'], y_pred_combined_3)\n",
    "\n",
    "# 打印结果\n",
    "print(\"=== Results for Different Frequency Groups ===\")\n",
    "print(\"Accuracy:\")\n",
    "print(f\"Group 1: {accuracy_1:.4f}\")\n",
    "print(f\"Group 2: {accuracy_2:.4f}\")\n",
    "print(f\"Group 3: {accuracy_3:.4f}\")\n",
    "print(\"\\nAUROC:\")\n",
    "print(f\"Group 1: {auroc_1:.4f}\")\n",
    "print(f\"Group 2: {auroc_2:.4f}\")\n",
    "print(f\"Group 3: {auroc_3:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
